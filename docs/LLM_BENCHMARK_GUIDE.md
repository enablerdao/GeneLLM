# LLMベンチマークガイド

## 概要

このガイドでは、C言語で実装された超軽量LLMシステムのベンチマーク方法について説明します。ベンチマークは、システムの応答品質と実行時間を測定するために使用されます。

## ベンチマークスクリプトの使い方

### 基本的な実行方法

```bash
# デフォルトの質問セットでベンチマーク実行
python3 scripts/benchmark.py

# デバッグモードでベンチマーク実行
python3 scripts/benchmark.py -d

# カスタム質問セットでベンチマーク実行
python3 scripts/benchmark.py -q scripts/custom_questions.json

# 結果を指定したファイルに保存
python3 scripts/benchmark.py -o my_results.json
```

### オプション

- `-d`, `--debug`: デバッグモードを有効にする（ルーターモデルの詳細な出力を表示）
- `-o`, `--output`: 結果を保存するJSONファイルのパスを指定
- `-q`, `--questions`: カスタム質問リストを含むJSONファイルのパスを指定

## カスタム質問セットの作成

カスタム質問セットは以下の形式のJSONファイルで定義できます：

```json
{
  "questions": [
    "質問1",
    "質問2",
    "質問3",
    ...
  ]
}
```

または、単純な質問の配列としても定義できます：

```json
[
  "質問1",
  "質問2",
  "質問3",
  ...
]
```

## 評価方法

ベンチマークスクリプトは、各質問に対する応答を以下の方法で評価します：

1. **キーワードマッチング**: 期待されるキーワードが応答に含まれているかをチェック
2. **実行時間測定**: 応答生成にかかる時間を測定
3. **スコア計算**: 一致したキーワードの割合（0.0〜1.0）を計算

## 結果の解釈

ベンチマーク結果は以下の情報を含みます：

- **各質問の詳細**: 質問、応答、実行時間、スコア
- **平均スコア**: すべての質問の平均評価スコア
- **平均実行時間**: 質問あたりの平均実行時間
- **合計実行時間**: すべての質問の処理にかかった合計時間

## 実行例

```
ベンチマークを開始します（質問数: 10）...

[1/10] 質問: Pythonでウェブスクレイピングをする方法を教えてください
応答: import requests
from bs4 import BeautifulSoup

def web_scraping_example():
    # スクレイピングするウェブサイトのURL
    url = "https://example.com"

    try:
        # ウェブページを取得
        response = requests.get(url)
...
実行時間: 0.00秒
評価スコア: 0.80

[2/10] 質問: Javaでファイル操作をする方法を教えてください
応答: import java.io.*;
import java.nio.file.*;
import java.util.Scanner;

public class FileOperationsExample {
...
実行時間: 0.00秒
評価スコア: 0.40

...

===== ベンチマーク結果 =====
合計実行時間: 0.02秒
平均実行時間: 0.00秒/質問
平均評価スコア: 0.72

結果を benchmark_results.json に保存しました。
```

## 結果の分析

ベンチマーク結果を分析する際は、以下の点に注目すると良いでしょう：

1. **高スコアの質問**: どのような質問で高いスコアが得られているか
2. **低スコアの質問**: どのような質問で改善が必要か
3. **実行時間の傾向**: 特に時間がかかる質問はあるか
4. **スコアの分布**: スコアが均一か、特定の分野に偏りがあるか

## ベンチマークの拡張

ベンチマークスクリプトは以下の方法で拡張できます：

1. **評価指標の追加**: BLEU、ROUGEなどの自然言語評価指標を追加
2. **質問カテゴリの導入**: 質問をカテゴリ別に分類して評価
3. **比較機能**: 異なるモデルバージョン間の比較
4. **自動最適化**: 結果に基づいてモデルパラメータを自動調整

## トラブルシューティング

- **UnicodeDecodeError**: 出力に非UTF-8文字が含まれている場合は、`errors='replace'`オプションを使用
- **実行時間が0秒**: 非常に高速な処理の場合、より精密な時間測定が必要
- **キーワードマッチングの問題**: 同義語や類似表現を考慮した評価方法に拡張

## まとめ

ベンチマークは、LLMシステムの性能を客観的に評価し、改善点を特定するための重要なツールです。定期的にベンチマークを実行し、システムの進化を追跡することをお勧めします。